{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages\n",
    "##Imports\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import openpyxl\n",
    "import numpy\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Does augmenting classifiers with structured data help?\n",
    "# Do it for both the baseline classical ML and transformers then compare\n",
    "# Try it with just structured data [0s and 1s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: Sample\n",
      "Sheet Name: Sentence_Labeling\n",
      "Sheet Name: ADR_Identified\n",
      "Sheet Name: ADR_Mapped\n",
      "Sheet Name: WD_Identified\n",
      "Sheet Name: WD-Mapped \n",
      "Sheet Name: SSI_Identified\n",
      "Sheet Name: SSI_Mapped\n",
      "Sheet Name: DI_Identified\n",
      "Sheet Name: DI_Mapped\n"
     ]
    }
   ],
   "source": [
    "## Reading in the PSYTar data set and parsing it\n",
    "\n",
    "## Use sentence_labelling sheet\n",
    "\n",
    "fileName=\".\\ONLINE_FORA\\PsyTAR_dataset.xlsx\"\n",
    "data=pd.ExcelFile(fileName)\n",
    "sheets={}\n",
    "for sheet in data.sheet_names:\n",
    "    sheets[sheet]=data.parse(sheet)\n",
    "\n",
    "## Remove the first two sheets (License and read_me)\n",
    "sheets.pop('License',None)\n",
    "sheets.pop('read_me',None)\n",
    "\n",
    "## This will print out the sheet names for the whole excel\n",
    "for sheet in sheets.keys():\n",
    "    print(f\"Sheet Name: {sheet}\")\n",
    "\n",
    "#To access a sheet, perform sheet['Sheet_Name']; e.g., sheets['Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2183)\t0.3560733570424169\n",
      "  (0, 2858)\t0.5335210557775061\n",
      "  (0, 2980)\t0.33695305203929327\n",
      "  (0, 4715)\t0.3577130194209486\n",
      "  (0, 4193)\t0.36113778160835414\n",
      "  (0, 2071)\t0.2627216248356759\n",
      "  (0, 5156)\t0.2390135798252401\n",
      "  (0, 1829)\t0.30083291559032393\n",
      "  (1, 2765)\t0.4585168729312828\n",
      "  (1, 1351)\t0.8886857021677111\n",
      "  (2, 2263)\t0.2708094866549267\n",
      "  (2, 4586)\t0.4316846093641784\n",
      "  (2, 5071)\t0.44358904667953863\n",
      "  (2, 4827)\t0.2570546169681927\n",
      "  (2, 3078)\t0.23875893121623276\n",
      "  (2, 4151)\t0.3207489298964512\n",
      "  (2, 1492)\t0.29911785906957045\n",
      "  (2, 1201)\t0.35264280744022497\n",
      "  (2, 4287)\t0.3220996041881179\n",
      "  (3, 4012)\t0.534375375933816\n",
      "  (3, 3326)\t0.5729355939201095\n",
      "  (3, 1018)\t0.39488574070665183\n",
      "  (3, 1237)\t0.3054771887014283\n",
      "  (3, 5)\t0.3700495936825698\n",
      "  (4, 4801)\t0.3601630582861626\n",
      "  :\t:\n",
      "  (6006, 3810)\t0.266723700884449\n",
      "  (6006, 278)\t0.30278988091992165\n",
      "  (6006, 4033)\t0.24160419308016043\n",
      "  (6006, 1558)\t0.24160419308016043\n",
      "  (6006, 2821)\t0.21617383387506503\n",
      "  (6006, 3470)\t0.20987895271102364\n",
      "  (6006, 1390)\t0.23609327417139986\n",
      "  (6006, 2098)\t0.1721949331238259\n",
      "  (6006, 2792)\t0.15461917912599263\n",
      "  (6007, 5221)\t0.40690224630890753\n",
      "  (6007, 1388)\t0.36244934695018927\n",
      "  (6007, 2358)\t0.40690224630890753\n",
      "  (6007, 987)\t0.36244934695018927\n",
      "  (6007, 5165)\t0.28822766104713454\n",
      "  (6007, 2896)\t0.29736053264983103\n",
      "  (6007, 1619)\t0.26742602182403663\n",
      "  (6007, 1809)\t0.3151406469723878\n",
      "  (6007, 2777)\t0.25257333627086354\n",
      "  (6008, 3452)\t0.462967378880836\n",
      "  (6008, 4290)\t0.4133719291682648\n",
      "  (6008, 1695)\t0.41770974043639536\n",
      "  (6008, 3642)\t0.462967378880836\n",
      "  (6008, 186)\t0.3151272227530411\n",
      "  (6008, 2777)\t0.24953491233016006\n",
      "  (6008, 5269)\t0.25375538243161966\n",
      "Number of Drug Types: 4\n",
      "          id  comment_id        drug_id  sentence_index  \\\n",
      "0        1.0         1.0      lexapro.1             1.0   \n",
      "1        2.0         1.0      lexapro.1             2.0   \n",
      "2        3.0         1.0      lexapro.1             3.0   \n",
      "3        4.0         1.0      lexapro.1             4.0   \n",
      "4        5.0         1.0      lexapro.1             5.0   \n",
      "...      ...         ...            ...             ...   \n",
      "6004  1545.0       228.0  effexorxr.228            14.0   \n",
      "6005  1546.0       228.0  effexorxr.228            15.0   \n",
      "6006  1547.0       228.0  effexorxr.228            16.0   \n",
      "6007  1548.0       228.0  effexorxr.228            17.0   \n",
      "6008  1549.0       228.0  effexorxr.228            18.0   \n",
      "\n",
      "                                              sentences  ADR   WD   EF  INF  \\\n",
      "0     extreme weight gain short-term memory loss hai...  1.0  0.0  0.0  0.0   \n",
      "1                                      detoxing lexapro  0.0  0.0  0.0  0.0   \n",
      "2     slowly cut dosage several months took vitamin ...  0.0  0.0  0.0  0.0   \n",
      "3                          10 days completely omg rough  0.0  0.0  0.0  0.0   \n",
      "4     flu-like symptoms dizziness major mood swings ...  0.0  1.0  0.0  0.0   \n",
      "...                                                 ...  ...  ...  ...  ...   \n",
      "6004                                increase dosage yet  0.0  0.0  0.0  0.0   \n",
      "6005           'm hoping able stay 75 mgs long possible  0.0  0.0  0.0  0.0   \n",
      "6006  reading withdrawals little scarey like said pe...  0.0  0.0  0.0  0.0   \n",
      "6007  effexor made huge difference life come experie...  0.0  0.0  1.0  0.0   \n",
      "6008              would small price pay able enjoy life  0.0  0.0  1.0  0.0   \n",
      "\n",
      "      SSI DI  Findings  others  rating category  drug_name  \n",
      "0     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "1     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "2     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "3     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "4     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "...   ... ..       ...     ...     ...      ...        ...  \n",
      "6004  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6005  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6006  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6007  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "6008  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "\n",
      "[6009 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "## Vectorize data into TF-IDF and preprocess data\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text=str(text)\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    tokens_clean=[t for t in tokens if (t not in stop_words) and (t not in punctuations)]\n",
    "    return ' '.join(tokens_clean)\n",
    "    \n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "punctuations=string.punctuation\n",
    "\n",
    "df=data.parse('Sentence_Labeling')\n",
    "df.drop(df.tail(1).index,inplace=True)\n",
    "df['drug_id']=df['drug_id'].str.lower()\n",
    "df['drug_name']=df['drug_id'].str.replace(r'\\.\\d+','',regex=True)\n",
    "df['sentences']=df['sentences'].apply(preprocess)\n",
    "df.fillna(0,inplace=True)\n",
    "unique_drug_count=df['drug_name'].nunique()\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidfSentences=tfidf.fit_transform(df['sentences'])\n",
    "\n",
    "print(tfidfSentences)\n",
    "\n",
    "print('Number of Drug Types:',unique_drug_count)\n",
    "print(df)\n",
    "\n",
    "## ADR: adverse drug reaction\n",
    "## WD: withdrawal symptom\n",
    "## EF: effective\n",
    "## INF: ineffective\n",
    "## SSI: Sign/symptom/illness - if report contains explicit SSI that patient experienced that are not a result of the drug\n",
    "## DI: drug indication - shows SSI that explicitly mentioned as being resolved because of drug consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = df['drug_name'].astype('category').cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_to_drug = {code: drug for code, drug in enumerate(category_mapping)}\n",
    "# print(code_to_drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(row):\n",
    "    labels = [\n",
    "        '[POS] adverse drug reaction' if row['ADR'] == 1 else '[NEG] adverse drug reaction',\n",
    "        '[POS] withdrawal symptom' if row['WD'] == 1 else '[NEG] withdrawal symptom',\n",
    "        '[POS] effective' if row['EF'] == 1 else '[NEG] effective',\n",
    "        '[POS] ineffective' if row['INF'] == 1 else '[NEG] ineffective',\n",
    "        '[POS] sign/symptom/illness' if row['SSI'] == 1 else '[NEG] sign/symptom/illness',\n",
    "        '[POS] drug indication' if row['DI'] == 1 else '[NEG] drug indication'\n",
    "    ]\n",
    "    return ' '.join(labels)\n",
    "\n",
    "# df['drug_name'] = df['drug_name'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = df['drug_name'].astype('category').cat.categories\n",
    "# print(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one is for the combined sentences -- Task 2 Feature 1\n",
    "\n",
    "df_word_label = df\n",
    "\n",
    "df_word_label['transformed_sentences'] = df.apply(lambda row: f\"{row['sentences']} {transform_labels(row)}\", axis=1)\n",
    "#print(df_word_label)\n",
    "\n",
    "## ADR: adverse drug reaction\n",
    "## WD: withdrawal symptom\n",
    "## EF: effective\n",
    "## INF: ineffective\n",
    "## SSI: Sign/symptom/illness - if report contains explicit SSI that patient experienced that are not a result of the drug\n",
    "## DI: drug indication - shows SSI that explicitly mentioned as being resolved because of drug consumption\n",
    "df_word_label.drop(columns=[\"id\", \"comment_id\", \"drug_id\", \"sentence_index\", \"Findings\", \"others\", \"rating\", \"category\",\"sentences\", \"ADR\", \"WD\", \"EF\", \"INF\", \"SSI\", \"DI\"], axis=1, inplace=True)\n",
    "\n",
    "df_word_label = df_word_label[['transformed_sentences', 'drug_name']]\n",
    "\n",
    "df_train, df_test = train_test_split(df_word_label, random_state=42, test_size=0.10, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_word_label, random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## This one is just for the text without transformed sentences -- Task 2 Feature 2\n",
    "# df_word_label=df\n",
    "\n",
    "\n",
    "# # x = df_word_label['sentences'].values\n",
    "# # y = df_word_label['drug_name'].astype('category').cat.codes.values\n",
    "# df_word_label.drop(columns=[\"id\", \"comment_id\", \"drug_id\", \"sentence_index\", \"Findings\", \"others\", \"rating\", \"category\", \"ADR\", \"WD\", \"EF\", \"INF\", \"SSI\", \"DI\"], axis=1, inplace=True)\n",
    "# df_word_label = df_word_label[['sentences', 'drug_name']]\n",
    "\n",
    "# # Split data\n",
    "# df_train, df_test = train_test_split(df_word_label, random_state=42, test_size=0.10, shuffle=True)\n",
    "# # split test into test and validation datasets\n",
    "# df_test, df_valid = train_test_split(df_word_label, random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## This one is just for the annotated dataset -- Task 2 Feature 3\n",
    "\n",
    "# df_word_label = df\n",
    "\n",
    "# df_word_label['transformed_labels'] = df_word_label.apply(transform_labels, axis=1)\n",
    "# print(df_word_label['transformed_labels'])\n",
    "\n",
    "# df_word_label.drop(columns=[\"id\", \"comment_id\", \"drug_id\", \"sentence_index\", \"Findings\", \"others\", \"rating\", \"category\",\"sentences\", \"ADR\", \"WD\", \"EF\", \"INF\", \"SSI\", \"DI\"], axis=1, inplace=True)\n",
    "# df_word_label = df_word_label[['transformed_labels', 'drug_name']]\n",
    "\n",
    "# # x = df_word_label['transformed_labels'].values\n",
    "# # y = df_word_label['drug_name'].astype('category').cat.codes.values\n",
    "\n",
    "# #Split data\n",
    "# df_train, df_test = train_test_split(df_word_label, random_state=42, test_size=0.10, shuffle=True)\n",
    "# # split test into test and validation datasets\n",
    "# df_test, df_valid = train_test_split(df_word_label, random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  transformed_sentences  drug_name\n",
      "0     extreme weight gain short-term memory loss hai...    lexapro\n",
      "1     detoxing lexapro [NEG] adverse drug reaction [...    lexapro\n",
      "2     slowly cut dosage several months took vitamin ...    lexapro\n",
      "3     10 days completely omg rough [NEG] adverse dru...    lexapro\n",
      "4     flu-like symptoms dizziness major mood swings ...    lexapro\n",
      "...                                                 ...        ...\n",
      "6004  increase dosage yet [NEG] adverse drug reactio...  effexorxr\n",
      "6005  'm hoping able stay 75 mgs long possible [NEG]...  effexorxr\n",
      "6006  reading withdrawals little scarey like said pe...  effexorxr\n",
      "6007  effexor made huge difference life come experie...  effexorxr\n",
      "6008  would small price pay able enjoy life [NEG] ad...  effexorxr\n",
      "\n",
      "[6009 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_word_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5408, 2), Test: (3004, 2), Valid: (3005, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lexapro', 'zoloft', 'cymbalta', 'effexorxr']\n"
     ]
    }
   ],
   "source": [
    "print(df['drug_name'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julev\\anaconda3\\envs\\cudaEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'lexapro':0,\n",
    "          'zoloft':1,\n",
    "          'cymbalta':2,\n",
    "          'effexorxr':3\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['drug_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['transformed_sentences']]\n",
    "                                ## change the df[''] depending on the feature\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julev\\anaconda3\\envs\\cudaEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 2704/2704 [04:45<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 1 | Train Loss:  0.791 | Train Accuracy:  0.263 | Val Loss:  0.769 | Val Accuracy:  0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [06:39<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 2 | Train Loss:  0.733 | Train Accuracy:  0.290 | Val Loss:  0.699 | Val Accuracy:  0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [06:37<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 3 | Train Loss:  0.680 | Train Accuracy:  0.363 | Val Loss:  0.657 | Val Accuracy:  0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [07:02<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 4 | Train Loss:  0.644 | Train Accuracy:  0.411 | Val Loss:  0.629 | Val Accuracy:  0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [06:56<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 5 | Train Loss:  0.604 | Train Accuracy:  0.471 | Val Loss:  0.583 | Val Accuracy:  0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [06:32<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 6 | Train Loss:  0.548 | Train Accuracy:  0.562 | Val Loss:  0.526 | Val Accuracy:  0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [06:41<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 7 | Train Loss:  0.470 | Train Accuracy:  0.652 | Val Loss:  0.458 | Val Accuracy:  0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [04:44<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model2_task2_feature1_model(unfrozen)\n",
      "Epochs: 8 | Train Loss:  0.378 | Train Accuracy:  0.756 | Val Loss:  0.390 | Val Accuracy:  0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2704/2704 [04:40<00:00,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "history = defaultdict(list)\n",
    "torch.cuda.empty_cache()\n",
    "def train(model, train_data, val_data, learning_rate, epochs, model_save_path):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2, shuffle=True)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    best_accuracy = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        train_acc = total_acc_train / len(train_data)\n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            if not os.path.exists(model_save_path):\n",
    "                os.makedirs(model_save_path)\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_path, 'model_state.bin'))\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "            best_accuracy = val_acc\n",
    "        \n",
    "        print(f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} | Train Accuracy: {train_acc: .3f} | Val Loss: {val_loss: .3f} | Val Accuracy: {val_acc: .3f}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_train_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total training time: {total_train_time:.2f} seconds\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return history\n",
    "\n",
    "EPOCHS = 20\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "model_save_path = './model2_task2_feature1_model(unfrozen)'\n",
    "\n",
    "train(model, df_train, df_valid, LR, EPOCHS, model_save_path)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julev\\anaconda3\\envs\\cudaEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained model (best model)\n",
    "model_load_path = './model2_task2_feature1_model(unfrozen)'\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(os.path.join(model_load_path, 'model_state.bin')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(df_test, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1502/1502 [00:48<00:00, 31.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.128 | Test Accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            test_label = test_label.to(device, dtype=torch.long)  # Ensure labels are of type long\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            loss = criterion(output, test_label)\n",
    "            total_loss_test += loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    avg_loss_test = total_loss_test / len(test_dataloader)\n",
    "    avg_acc_test = total_acc_test / len(test_data)\n",
    "\n",
    "    print(f'Test Loss: {avg_loss_test:.3f} | Test Accuracy: {avg_acc_test:.3f}')\n",
    "evaluate(model, df_test)\n",
    "\n",
    "# labels = {'lexapro':0,\n",
    "#           'zoloft':1,\n",
    "#           'cymbalta':2,\n",
    "#           'effexorxr':3\n",
    "#           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1502/1502 [00:48<00:00, 31.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       720\n",
      "           1       0.99      0.93      0.96       632\n",
      "           2       0.98      0.98      0.98       871\n",
      "           3       0.95      0.99      0.97       781\n",
      "\n",
      "    accuracy                           0.98      3004\n",
      "   macro avg       0.98      0.97      0.97      3004\n",
      "weighted avg       0.98      0.98      0.97      3004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_prediction(model, dataloader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if use_cuda else torch.device('cpu')\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_input, data_label in tqdm(dataloader):\n",
    "            data_label = data_label.to(device)\n",
    "            mask = data_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            preds = output.argmax(dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(data_label.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_test is a DataFrame containing test data with columns 'drug_name' and 'transformed_sentences'\n",
    "test_dataset = Dataset(df_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load(os.path.join(model_save_path, 'model_state.bin')))\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels = get_prediction(model, test_dataloader)\n",
    "\n",
    "# You can then compare the predictions with the true labels or use them for further evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2183)\t0.3560733570424169\n",
      "  (0, 2858)\t0.5335210557775061\n",
      "  (0, 2980)\t0.33695305203929327\n",
      "  (0, 4715)\t0.3577130194209486\n",
      "  (0, 4193)\t0.36113778160835414\n",
      "  (0, 2071)\t0.2627216248356759\n",
      "  (0, 5156)\t0.2390135798252401\n",
      "  (0, 1829)\t0.30083291559032393\n",
      "  (1, 2765)\t0.4585168729312828\n",
      "  (1, 1351)\t0.8886857021677111\n",
      "  (2, 2263)\t0.2708094866549267\n",
      "  (2, 4586)\t0.4316846093641784\n",
      "  (2, 5071)\t0.44358904667953863\n",
      "  (2, 4827)\t0.2570546169681927\n",
      "  (2, 3078)\t0.23875893121623276\n",
      "  (2, 4151)\t0.3207489298964512\n",
      "  (2, 1492)\t0.29911785906957045\n",
      "  (2, 1201)\t0.35264280744022497\n",
      "  (2, 4287)\t0.3220996041881179\n",
      "  (3, 4012)\t0.534375375933816\n",
      "  (3, 3326)\t0.5729355939201095\n",
      "  (3, 1018)\t0.39488574070665183\n",
      "  (3, 1237)\t0.3054771887014283\n",
      "  (3, 5)\t0.3700495936825698\n",
      "  (4, 4801)\t0.3601630582861626\n",
      "  :\t:\n",
      "  (6006, 3810)\t0.266723700884449\n",
      "  (6006, 278)\t0.30278988091992165\n",
      "  (6006, 4033)\t0.24160419308016043\n",
      "  (6006, 1558)\t0.24160419308016043\n",
      "  (6006, 2821)\t0.21617383387506503\n",
      "  (6006, 3470)\t0.20987895271102364\n",
      "  (6006, 1390)\t0.23609327417139986\n",
      "  (6006, 2098)\t0.1721949331238259\n",
      "  (6006, 2792)\t0.15461917912599263\n",
      "  (6007, 5221)\t0.40690224630890753\n",
      "  (6007, 1388)\t0.36244934695018927\n",
      "  (6007, 2358)\t0.40690224630890753\n",
      "  (6007, 987)\t0.36244934695018927\n",
      "  (6007, 5165)\t0.28822766104713454\n",
      "  (6007, 2896)\t0.29736053264983103\n",
      "  (6007, 1619)\t0.26742602182403663\n",
      "  (6007, 1809)\t0.3151406469723878\n",
      "  (6007, 2777)\t0.25257333627086354\n",
      "  (6008, 3452)\t0.462967378880836\n",
      "  (6008, 4290)\t0.4133719291682648\n",
      "  (6008, 1695)\t0.41770974043639536\n",
      "  (6008, 3642)\t0.462967378880836\n",
      "  (6008, 186)\t0.3151272227530411\n",
      "  (6008, 2777)\t0.24953491233016006\n",
      "  (6008, 5269)\t0.25375538243161966\n",
      "Number of Drug Types: 4\n",
      "          id  comment_id        drug_id  sentence_index  \\\n",
      "0        1.0         1.0      lexapro.1             1.0   \n",
      "1        2.0         1.0      lexapro.1             2.0   \n",
      "2        3.0         1.0      lexapro.1             3.0   \n",
      "3        4.0         1.0      lexapro.1             4.0   \n",
      "4        5.0         1.0      lexapro.1             5.0   \n",
      "...      ...         ...            ...             ...   \n",
      "6004  1545.0       228.0  effexorxr.228            14.0   \n",
      "6005  1546.0       228.0  effexorxr.228            15.0   \n",
      "6006  1547.0       228.0  effexorxr.228            16.0   \n",
      "6007  1548.0       228.0  effexorxr.228            17.0   \n",
      "6008  1549.0       228.0  effexorxr.228            18.0   \n",
      "\n",
      "                                              sentences  ADR   WD   EF  INF  \\\n",
      "0     extreme weight gain short-term memory loss hai...  1.0  0.0  0.0  0.0   \n",
      "1                                      detoxing lexapro  0.0  0.0  0.0  0.0   \n",
      "2     slowly cut dosage several months took vitamin ...  0.0  0.0  0.0  0.0   \n",
      "3                          10 days completely omg rough  0.0  0.0  0.0  0.0   \n",
      "4     flu-like symptoms dizziness major mood swings ...  0.0  1.0  0.0  0.0   \n",
      "...                                                 ...  ...  ...  ...  ...   \n",
      "6004                                increase dosage yet  0.0  0.0  0.0  0.0   \n",
      "6005           'm hoping able stay 75 mgs long possible  0.0  0.0  0.0  0.0   \n",
      "6006  reading withdrawals little scarey like said pe...  0.0  0.0  0.0  0.0   \n",
      "6007  effexor made huge difference life come experie...  0.0  0.0  1.0  0.0   \n",
      "6008              would small price pay able enjoy life  0.0  0.0  1.0  0.0   \n",
      "\n",
      "      SSI DI  Findings  others  rating category  drug_name  \n",
      "0     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "1     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "2     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "3     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "4     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "...   ... ..       ...     ...     ...      ...        ...  \n",
      "6004  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6005  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6006  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6007  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "6008  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "\n",
      "[6009 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess(text):\n",
    "    text=str(text)\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    tokens_clean=[t for t in tokens if (t not in stop_words) and (t not in punctuations)]\n",
    "    return ' '.join(tokens_clean)\n",
    "    \n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "punctuations=string.punctuation\n",
    "\n",
    "df=data.parse('Sentence_Labeling')\n",
    "df.drop(df.tail(1).index,inplace=True)\n",
    "df['drug_id']=df['drug_id'].str.lower()\n",
    "df['drug_name']=df['drug_id'].str.replace(r'\\.\\d+','',regex=True)\n",
    "df['sentences']=df['sentences'].apply(preprocess)\n",
    "df.fillna(0,inplace=True)\n",
    "unique_drug_count=df['drug_name'].nunique()\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidfSentences=tfidf.fit_transform(df['sentences'])\n",
    "\n",
    "print(tfidfSentences)\n",
    "\n",
    "print('Number of Drug Types:',unique_drug_count)\n",
    "print(df)\n",
    "\n",
    "## ADR: adverse drug reaction\n",
    "## WD: withdrawal symptom\n",
    "## EF: effective\n",
    "## INF: ineffective\n",
    "## SSI: Sign/symptom/illness - if report contains explicit SSI that patient experienced that are not a result of the drug\n",
    "## DI: drug indication - shows SSI that explicitly mentioned as being resolved because of drug consumption\n",
    "\n",
    "# ## This one is just for the text without transformed sentences -- Task 2 Feature 2\n",
    "df_word_label=df\n",
    "\n",
    "\n",
    "# x = df_word_label['sentences'].values\n",
    "# y = df_word_label['drug_name'].astype('category').cat.codes.values\n",
    "df_word_label.drop(columns=[\"id\", \"comment_id\", \"drug_id\", \"sentence_index\", \"Findings\", \"others\", \"rating\", \"category\", \"ADR\", \"WD\", \"EF\", \"INF\", \"SSI\", \"DI\"], axis=1, inplace=True)\n",
    "df_word_label = df_word_label[['sentences', 'drug_name']]\n",
    "\n",
    "# Split data\n",
    "df_train, df_test = train_test_split(df_word_label, random_state=42, test_size=0.10, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_word_label, random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julev\\anaconda3\\envs\\cudaEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'lexapro':0,\n",
    "          'zoloft':1,\n",
    "          'cymbalta':2,\n",
    "          'effexorxr':3\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['drug_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['sentences']]\n",
    "                                ## change the df[''] depending on the feature\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2704 [00:10<3:46:42,  5.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m     98\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model2_task2_feature2_model(unfrozen)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 100\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs, model_save_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m total_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m---> 34\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     mask \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "history = defaultdict(list)\n",
    "torch.cuda.empty_cache()\n",
    "def train(model, train_data, val_data, learning_rate, epochs, model_save_path):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2, shuffle=True)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    best_accuracy = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        train_acc = total_acc_train / len(train_data)\n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            if not os.path.exists(model_save_path):\n",
    "                os.makedirs(model_save_path)\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_path, 'model_state.bin'))\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "            best_accuracy = val_acc\n",
    "        \n",
    "        print(f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} | Train Accuracy: {train_acc: .3f} | Val Loss: {val_loss: .3f} | Val Accuracy: {val_acc: .3f}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_train_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total training time: {total_train_time:.2f} seconds\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return history\n",
    "\n",
    "EPOCHS = 20\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "model_save_path = './model2_task2_feature2_model(unfrozen)'\n",
    "\n",
    "train(model, df_train, df_valid, LR, EPOCHS, model_save_path)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model (best model)\n",
    "model_load_path = './model2_task2_feature2_model(unfrozen)'\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(os.path.join(model_load_path, 'model_state.bin')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(df_test, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            test_label = test_label.to(device, dtype=torch.long)  # Ensure labels are of type long\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            loss = criterion(output, test_label)\n",
    "            total_loss_test += loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    avg_loss_test = total_loss_test / len(test_dataloader)\n",
    "    avg_acc_test = total_acc_test / len(test_data)\n",
    "\n",
    "    print(f'Test Loss: {avg_loss_test:.3f} | Test Accuracy: {avg_acc_test:.3f}')\n",
    "evaluate(model, df_test)\n",
    "\n",
    "# labels = {'lexapro':0,\n",
    "#           'zoloft':1,\n",
    "#           'cymbalta':2,\n",
    "#           'effexorxr':3\n",
    "#           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_prediction(model, dataloader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if use_cuda else torch.device('cpu')\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_input, data_label in tqdm(dataloader):\n",
    "            data_label = data_label.to(device)\n",
    "            mask = data_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            preds = output.argmax(dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(data_label.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_test is a DataFrame containing test data with columns 'drug_name' and 'transformed_sentences'\n",
    "test_dataset = Dataset(df_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load(os.path.join(model_save_path, 'model_state.bin')))\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels = get_prediction(model, test_dataloader)\n",
    "\n",
    "# You can then compare the predictions with the true labels or use them for further evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2183)\t0.3560733570424169\n",
      "  (0, 2858)\t0.5335210557775061\n",
      "  (0, 2980)\t0.33695305203929327\n",
      "  (0, 4715)\t0.3577130194209486\n",
      "  (0, 4193)\t0.36113778160835414\n",
      "  (0, 2071)\t0.2627216248356759\n",
      "  (0, 5156)\t0.2390135798252401\n",
      "  (0, 1829)\t0.30083291559032393\n",
      "  (1, 2765)\t0.4585168729312828\n",
      "  (1, 1351)\t0.8886857021677111\n",
      "  (2, 2263)\t0.2708094866549267\n",
      "  (2, 4586)\t0.4316846093641784\n",
      "  (2, 5071)\t0.44358904667953863\n",
      "  (2, 4827)\t0.2570546169681927\n",
      "  (2, 3078)\t0.23875893121623276\n",
      "  (2, 4151)\t0.3207489298964512\n",
      "  (2, 1492)\t0.29911785906957045\n",
      "  (2, 1201)\t0.35264280744022497\n",
      "  (2, 4287)\t0.3220996041881179\n",
      "  (3, 4012)\t0.534375375933816\n",
      "  (3, 3326)\t0.5729355939201095\n",
      "  (3, 1018)\t0.39488574070665183\n",
      "  (3, 1237)\t0.3054771887014283\n",
      "  (3, 5)\t0.3700495936825698\n",
      "  (4, 4801)\t0.3601630582861626\n",
      "  :\t:\n",
      "  (6006, 3810)\t0.266723700884449\n",
      "  (6006, 278)\t0.30278988091992165\n",
      "  (6006, 4033)\t0.24160419308016043\n",
      "  (6006, 1558)\t0.24160419308016043\n",
      "  (6006, 2821)\t0.21617383387506503\n",
      "  (6006, 3470)\t0.20987895271102364\n",
      "  (6006, 1390)\t0.23609327417139986\n",
      "  (6006, 2098)\t0.1721949331238259\n",
      "  (6006, 2792)\t0.15461917912599263\n",
      "  (6007, 5221)\t0.40690224630890753\n",
      "  (6007, 1388)\t0.36244934695018927\n",
      "  (6007, 2358)\t0.40690224630890753\n",
      "  (6007, 987)\t0.36244934695018927\n",
      "  (6007, 5165)\t0.28822766104713454\n",
      "  (6007, 2896)\t0.29736053264983103\n",
      "  (6007, 1619)\t0.26742602182403663\n",
      "  (6007, 1809)\t0.3151406469723878\n",
      "  (6007, 2777)\t0.25257333627086354\n",
      "  (6008, 3452)\t0.462967378880836\n",
      "  (6008, 4290)\t0.4133719291682648\n",
      "  (6008, 1695)\t0.41770974043639536\n",
      "  (6008, 3642)\t0.462967378880836\n",
      "  (6008, 186)\t0.3151272227530411\n",
      "  (6008, 2777)\t0.24953491233016006\n",
      "  (6008, 5269)\t0.25375538243161966\n",
      "Number of Drug Types: 4\n",
      "          id  comment_id        drug_id  sentence_index  \\\n",
      "0        1.0         1.0      lexapro.1             1.0   \n",
      "1        2.0         1.0      lexapro.1             2.0   \n",
      "2        3.0         1.0      lexapro.1             3.0   \n",
      "3        4.0         1.0      lexapro.1             4.0   \n",
      "4        5.0         1.0      lexapro.1             5.0   \n",
      "...      ...         ...            ...             ...   \n",
      "6004  1545.0       228.0  effexorxr.228            14.0   \n",
      "6005  1546.0       228.0  effexorxr.228            15.0   \n",
      "6006  1547.0       228.0  effexorxr.228            16.0   \n",
      "6007  1548.0       228.0  effexorxr.228            17.0   \n",
      "6008  1549.0       228.0  effexorxr.228            18.0   \n",
      "\n",
      "                                              sentences  ADR   WD   EF  INF  \\\n",
      "0     extreme weight gain short-term memory loss hai...  1.0  0.0  0.0  0.0   \n",
      "1                                      detoxing lexapro  0.0  0.0  0.0  0.0   \n",
      "2     slowly cut dosage several months took vitamin ...  0.0  0.0  0.0  0.0   \n",
      "3                          10 days completely omg rough  0.0  0.0  0.0  0.0   \n",
      "4     flu-like symptoms dizziness major mood swings ...  0.0  1.0  0.0  0.0   \n",
      "...                                                 ...  ...  ...  ...  ...   \n",
      "6004                                increase dosage yet  0.0  0.0  0.0  0.0   \n",
      "6005           'm hoping able stay 75 mgs long possible  0.0  0.0  0.0  0.0   \n",
      "6006  reading withdrawals little scarey like said pe...  0.0  0.0  0.0  0.0   \n",
      "6007  effexor made huge difference life come experie...  0.0  0.0  1.0  0.0   \n",
      "6008              would small price pay able enjoy life  0.0  0.0  1.0  0.0   \n",
      "\n",
      "      SSI DI  Findings  others  rating category  drug_name  \n",
      "0     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "1     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "2     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "3     0.0  0       0.0       1     1.0     ssri    lexapro  \n",
      "4     0.0  0       0.0       0     1.0     ssri    lexapro  \n",
      "...   ... ..       ...     ...     ...      ...        ...  \n",
      "6004  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6005  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6006  0.0  0       0.0       1     5.0     snri  effexorxr  \n",
      "6007  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "6008  0.0  0       0.0       0     5.0     snri  effexorxr  \n",
      "\n",
      "[6009 rows x 16 columns]\n",
      "0       [POS] adverse drug reaction [NEG] withdrawal s...\n",
      "1       [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "2       [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "3       [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "4       [NEG] adverse drug reaction [POS] withdrawal s...\n",
      "                              ...                        \n",
      "6004    [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "6005    [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "6006    [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "6007    [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "6008    [NEG] adverse drug reaction [NEG] withdrawal s...\n",
      "Name: transformed_labels, Length: 6009, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## This one is just for the annotated dataset -- Task 2 Feature 3\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess(text):\n",
    "    text=str(text)\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    tokens_clean=[t for t in tokens if (t not in stop_words) and (t not in punctuations)]\n",
    "    return ' '.join(tokens_clean)\n",
    "    \n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "punctuations=string.punctuation\n",
    "\n",
    "df=data.parse('Sentence_Labeling')\n",
    "df.drop(df.tail(1).index,inplace=True)\n",
    "df['drug_id']=df['drug_id'].str.lower()\n",
    "df['drug_name']=df['drug_id'].str.replace(r'\\.\\d+','',regex=True)\n",
    "df['sentences']=df['sentences'].apply(preprocess)\n",
    "df.fillna(0,inplace=True)\n",
    "unique_drug_count=df['drug_name'].nunique()\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidfSentences=tfidf.fit_transform(df['sentences'])\n",
    "\n",
    "print(tfidfSentences)\n",
    "\n",
    "print('Number of Drug Types:',unique_drug_count)\n",
    "print(df)\n",
    "df_word_label = df\n",
    "\n",
    "df_word_label['transformed_labels'] = df_word_label.apply(transform_labels, axis=1)\n",
    "print(df_word_label['transformed_labels'])\n",
    "\n",
    "df_word_label.drop(columns=[\"id\", \"comment_id\", \"drug_id\", \"sentence_index\", \"Findings\", \"others\", \"rating\", \"category\",\"sentences\", \"ADR\", \"WD\", \"EF\", \"INF\", \"SSI\", \"DI\"], axis=1, inplace=True)\n",
    "df_word_label = df_word_label[['transformed_labels', 'drug_name']]\n",
    "\n",
    "# x = df_word_label['transformed_labels'].values\n",
    "# y = df_word_label['drug_name'].astype('category').cat.codes.values\n",
    "\n",
    "#Split data\n",
    "df_train, df_test = train_test_split(df_word_label, random_state=42, test_size=0.10, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_word_label, random_state=42, test_size=0.50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julev\\anaconda3\\envs\\cudaEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'lexapro':0,\n",
    "          'zoloft':1,\n",
    "          'cymbalta':2,\n",
    "          'effexorxr':3\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['drug_name']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['transformed_labels']]\n",
    "                                ## change the df[''] depending on the feature\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2704 [00:12<2:24:58,  3.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m     98\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model2_task2_feature3_model(unfrozen)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 100\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[1;32mIn[31], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs, model_save_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m total_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m---> 34\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     mask \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "history = defaultdict(list)\n",
    "torch.cuda.empty_cache()\n",
    "def train(model, train_data, val_data, learning_rate, epochs, model_save_path):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2, shuffle=True)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    best_accuracy = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        train_acc = total_acc_train / len(train_data)\n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            if not os.path.exists(model_save_path):\n",
    "                os.makedirs(model_save_path)\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_path, 'model_state.bin'))\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "            best_accuracy = val_acc\n",
    "        \n",
    "        print(f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} | Train Accuracy: {train_acc: .3f} | Val Loss: {val_loss: .3f} | Val Accuracy: {val_acc: .3f}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_train_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total training time: {total_train_time:.2f} seconds\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return history\n",
    "\n",
    "EPOCHS = 20\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "model_save_path = './model2_task2_feature3_model(unfrozen)'\n",
    "\n",
    "train(model, df_train, df_valid, LR, EPOCHS, model_save_path)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model (best model)\n",
    "model_load_path = './model2_task2_feature3_model(unfrozen)'\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(os.path.join(model_load_path, 'model_state.bin')))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(df_test, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            test_label = test_label.to(device, dtype=torch.long)  # Ensure labels are of type long\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            loss = criterion(output, test_label)\n",
    "            total_loss_test += loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    avg_loss_test = total_loss_test / len(test_dataloader)\n",
    "    avg_acc_test = total_acc_test / len(test_data)\n",
    "\n",
    "    print(f'Test Loss: {avg_loss_test:.3f} | Test Accuracy: {avg_acc_test:.3f}')\n",
    "evaluate(model, df_test)\n",
    "\n",
    "# labels = {'lexapro':0,\n",
    "#           'zoloft':1,\n",
    "#           'cymbalta':2,\n",
    "#           'effexorxr':3\n",
    "#           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_prediction(model, dataloader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda') if use_cuda else torch.device('cpu')\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_input, data_label in tqdm(dataloader):\n",
    "            data_label = data_label.to(device)\n",
    "            mask = data_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            preds = output.argmax(dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(data_label.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_test is a DataFrame containing test data with columns 'drug_name' and 'transformed_sentences'\n",
    "test_dataset = Dataset(df_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load(os.path.join(model_save_path, 'model_state.bin')))\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels = get_prediction(model, test_dataloader)\n",
    "\n",
    "# You can then compare the predictions with the true labels or use them for further evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
